{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework - Bayesian modeling - Part B (40 points) \n",
    "## Probabilistic programs for productive reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by *Brenden Lake* and *Todd Gureckis*  \n",
    "Computational Cognitive Modeling  \n",
    "NYU class webpage: https://brendenlake.github.io/CCM-site/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "This homework is due before midnight on Monday, April 4. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People can reason in very flexible and sophisticated ways. Let's consider an example that was introduced in Gerstenberg and Goodman (2012; see below for reference). Imagine that Brenden and Todd are playing tennis together, and Brenden wins the game. You might suspect that Brenden is a strong player, but you may also not think much of it, since it was only one game and we don't know much about Todd's ability.\n",
    "\n",
    "Now imagine that you also learn that Todd has recently played against two other faculty members in the Psychology department, and he won both of those games. You would now have a higher opinion of Brenden's skill.\n",
    "\n",
    "Now, say you also learn that Todd was feeling very lazy in his game against Brenden. This could change your opinion yet again about Brenden's skill.\n",
    "\n",
    "In this notebook, you will get hands on experience using simple probabilistic programs and Bayesian inference to model these patterns of reasoning. Probabilistic programs are a powerful way to write Bayesian models, and they are especially useful when the prior distribution is more complex than a list of hypotheses, or is inconvenient to represent with a probabilistic graphical model.\n",
    "\n",
    "Probabilistic programming is an active area of research. There are many specially designed probabilistic programming languages such as [WebPPL](http://webppl.org/) and [Church](http://v1.probmods.org/). Recently, new languages have been introduced that combine aspects of probabilistic programming and neural networks, such as [Pyro](http://pyro.ai/), and [Edward](http://edwardlib.org/). Rather than using a particular language, we will use vanilla Python to express an interesting probability distribution as a probabilistic program, and you will be asked to write your own rejection sampler for inference. More generally, an important component of the appeal of probabilistic programming is that when using a specialized language, you can take advantage of general algorithms for Bayesian inference without having to implement your own.\n",
    "\n",
    "Great, let's proceed with the probabilistic model of tennis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The Bayesian tennis game was introduced by Tobi Gerstenberg and Noah Goodman in the following material:\n",
    "<br>\n",
    "<ul>\n",
    "    <li>Gerstenberg, T., & Goodman, N. (2012). Ping Pong in Church: Productive use of concepts in human probabilistic inference. In Proceedings of the Annual Meeting of the Cognitive Science Society.</li>\n",
    "    <li>Probabilistic models of cognition online book (Chapter 3) (https://probmods.org/chapters/03-conditioning.html)</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic model\n",
    "\n",
    "The generative model can be described as follows. There are various players engaged in a tennis tournament. Matches can be played either as a singles match (Player A vs. Player B) or as a doubles match (Player A and Player B vs. Player C and Player D).\n",
    "\n",
    "Each player has a latent `strength` value which describes his or her skill at tennis. This quantity is unobserved for each player, and it is a persistent property in the world. Therefore, the `strength` stays the same across the entire set of matches.\n",
    "\n",
    "A match is decided by whichever team has more `team_strength`. Thus, if it's just Player A vs. Player B, the stronger player will win. If it's a doubles match, `team_strength` is the sum of the strengths determines which team will be the `winner`. However, there is an additional complication. On occasion (with probability 0.1), a player becomes `lazy`, in that he or she doesn't try very hard for this particular match. For the purpose of this match, his or her `strength` is reduced by half. Importantly, this is a temporary (non-persistent) state which is does not effect the next match.\n",
    "\n",
    "This completes our generative model of how the data is produced. In this assignment, we will use Bayesian inference to reason about latent parameters in the model, such as reasoning about a player's strength given observations of his or her performance.\n",
    "\n",
    "### Concepts as programs\n",
    "**A powerful idea is that we can model concepts like `strength`, `lazy`, `team_strength`, `winner`, and `beat` as programs, usually simple stochastic functions that operate on inputs and produce outputs.** You will see many examples of this in the code below. Under this view, the meaning of a \"word\" comes from the semantics of the program, and how the program interact with eachother. Can all of our everyday concepts be represented as programs? It's an open question, and the excitement around probabilistic programming is that it provides a toolkit for exploring this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent properties\n",
    "The strength of each player is the only persistent property. In the code below, we create a `world` class which stores the persistent states. In this case, it's simply a dictionary `dict_strength` that maps each player's name to his or her strength. Conveniently, the world class gives us a method `clear` that resets the world state, which is useful when we want to clear everything and produce a fresh sample of the world.\n",
    "\n",
    "The `strength` function takes a player's `name` and queries the world `W` for the appropriate strength value. If it's a new player, their strength is sampled from a Gaussian distribution (with $\\mu=10$ and $\\sigma=3$) and stored persistently in the world state. As you can see, this captures something about our intuitive notion of strength as a persistent property.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class world():\n",
    "    def __init__(self):\n",
    "        self.dict_strength = {}\n",
    "    def clear(self): # used when sampling over possible world\n",
    "        self.dict_strength = {}\n",
    "\n",
    "W = world()\n",
    "\n",
    "def strength(name):\n",
    "    if name not in W.dict_strength:\n",
    "        W.dict_strength[name] = abs(random.gauss(10,3))\n",
    "    return W.dict_strength[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing team strength\n",
    "Next is the `lazy` function. When the lazy function is called on the `name` of a particular player, the answer is computed fresh each time (and is not stored persistently like strength).\n",
    "\n",
    "The total strength of a team `team_strength` takes a list of names `team` and computes the aggregate strength. This is a simple sum across the team members, with a special case for lazy team members. For a game like tennis, this program captures aspects of what we mean when we think about \"the strength of a team\" -- although simplified, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazy(name):\n",
    "    return random.random() < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_strength(team):\n",
    "    # team : list of names\n",
    "    mysum = 0.\n",
    "    for name in team:\n",
    "        if lazy(name):\n",
    "            mysum += (strength(name) / 2.)\n",
    "        else:\n",
    "            mysum += strength(name)\n",
    "    return mysum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the winner\n",
    "The `winner` of a match returns the team with a higher strength value. Again, we can represent this as a very simple function of `team_strength`.\n",
    "\n",
    "Finally, the function `beat` checks whether `team1` outperformed `team2` (returning `True`) or not (returning `False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(team1,team2):\n",
    "    # team1 : list of names\n",
    "    # team2 : list of names\n",
    "    if team_strength(team1) > team_strength(team2):\n",
    "        return team1\n",
    "    else:\n",
    "        return team2\n",
    "\n",
    "def beat(team1,team2):\n",
    "    return winner(team1,team2) == team1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic inference\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 1 (15 points) </h3>\n",
    "<br>\n",
    "Your first task is to complete the missing code in the `rejection_sampler` function below to perform probabilistic inference in the model. You give it a list of function handles `list_f_conditions` which represent the data we are conditioning on, and thus these functions must evaluate to `True` in the current state of the world. If they do, then you want to grab the variable of interest using the function handle `f_return` and store it in the `samples` vector, which is returned as a numpy array.\n",
    "\n",
    "Please fill out the function below.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Note: A function handle `f_return` is a pointer to a function which can be executed with the syntax `f_return()`. We need to pass handles, rather than pre-executed functions, so the rejection sampler can control for itself when to execute the functions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sampler(f_return, list_f_conditions, nsamp=10000):\n",
    "    # Input\n",
    "    #  f_return : function handle that grabs the variable of interest when executed\n",
    "    #  list_f_conditions: list of conditions (function handles) that we are assuming are True\n",
    "    #  nsamp : number of attempted samples (default is 10000)\n",
    "    # Output\n",
    "    #  samples : (as a numpy-array) where length is the number of actual, accepted samples\n",
    "    samples = []\n",
    "    for i in range(nsamp):        \n",
    "        # TODO : your code goes here (don't forget to call W.clear() before each attempted sample)\n",
    "        W.clear()\n",
    "        check_true = True\n",
    "        for func in list_f_conditions:\n",
    "            if func() == False:\n",
    "                check_true = False\n",
    "        if check_true == True:\n",
    "            samples.append(f_return())\n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to test your rejection sampler. Let's assume Bob and Mary beat Tom and Sue in their tennis match. Also, Bob and Sue beat Tom and Jim. What is our mean estimate of Bob's strength? (The right answer is around 11.86, but you won't get that exactly. Check that you are in the same ballpark). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of Bob's strength: mean = 11.861837497815158; effective n = 14177\n"
     ]
    }
   ],
   "source": [
    "f_return = lambda : strength('bob')\n",
    "list_f_conditions = [lambda : beat( ['bob', 'mary'],['tom', 'sue'] ), lambda : beat( ['bob', 'sue'],  ['tom', 'jim'] )]\n",
    "samples = rejection_sampler(f_return, list_f_conditions, nsamp=50000)\n",
    "mean_strength = np.mean(samples)\n",
    "print(\"Estimate of Bob's strength: mean = \" + str(mean_strength) + \"; effective n = \" + str(len(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing judgments from people and the model\n",
    "We want to explore how well the model matches human judgments of strength. In the table below, there are six different doubles tennis tournaments. Each tournament consists of three doubles matches, and each letter represents a different player. Thus, in the first tournament, the first match shows Player A and Player B winning against Player C and Player D. In the second match, Player A and Player B win against Player E and F. Given the evidence, how strong is Player A in Scenario 1? How strong is Player A in Scenario 2? The data in the different scenarios should be considered separate (they are alternative possible worlds, rather than sequential tournaments).\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "For each tournament, rate how strong you think Player A is using a 1 to 7 scale, where 1 is the weakest and 7 is the strongest. Also, explain the scenario to a friend and ask for their ratings as well. Be sure to mention that sometimes a player is lazy (about 10 percent of the time) and doesn't perform as well. \n",
    "</div>\n",
    "\n",
    "<img src=\"images/tennis_games.jpeg\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : YOUR DATA GOES HERE\n",
    "subject1_pred = np.array([5,6,6,4,6,7])\n",
    "subject2_pred = np.array([4,5,6,6,7,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will use your rejection sampler to predict the strength of Player A in all six of the scenarios. These six numbers will be stored in the array `model_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1\n",
      "  sample mean : 12.079430666758954; n=2146\n",
      "Scenario 2\n",
      "  sample mean : 11.96976391904173; n=2215\n",
      "Scenario 3\n",
      "  sample mean : 12.172242731434608; n=743\n",
      "Scenario 4\n",
      "  sample mean : 10.535158536445117; n=2740\n",
      "Scenario 5\n",
      "  sample mean : 12.416685235284469; n=1689\n",
      "Scenario 6\n",
      "  sample mean : 13.074950254182998; n=1262\n"
     ]
    }
   ],
   "source": [
    "model_pred = []\n",
    "\n",
    "f_return = lambda : strength('A')\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['C', 'D'] ), lambda : beat( ['A', 'B'],['E', 'F'] ), lambda : beat( ['A', 'B'],  ['G', 'H'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 1\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['E', 'F'] ), lambda : beat( ['A', 'C'],['E', 'G'] ), lambda : beat( ['A', 'D'],  ['E', 'H'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 2\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['E', 'F'] ), lambda : beat(['E', 'F'], ['B', 'C'] ), lambda : beat( ['E', 'F'], ['B', 'D'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 3\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['E', 'F'] ), lambda : beat( ['B', 'C'],['E', 'F'] ), lambda : beat( ['B', 'D'],  ['E', 'F'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 4\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['E', 'F'] ), lambda : beat( ['A', 'C'],['G', 'H'] ), lambda : beat( ['A', 'D'],  ['I', 'J'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 5\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['C', 'D'] ), lambda : beat( ['A', 'C'],['B', 'D'] ), lambda : beat( ['A', 'D'],  ['B', 'C'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 6\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a bar graph to compare the human and model predictions for Player A's strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between human and model predictions; r = 0.691\n"
     ]
    }
   ],
   "source": [
    "def normalize(v):\n",
    "    # scale vector v to have min 0 and max 1\n",
    "    v = v - np.min(v)\n",
    "    v = v / np.max(v)\n",
    "    return v\n",
    "\n",
    "human_pred_norm = normalize((subject1_pred+subject2_pred)/2.)\n",
    "model_pred_norm = normalize(model_pred)\n",
    "\n",
    "# compare predictions from people vs. Bayesian mdoel\n",
    "mybottom = -0.1\n",
    "width = 0.35 \n",
    "plt.figure(1)\n",
    "plt.bar(np.arange(len(human_pred_norm)),human_pred_norm-mybottom, width, bottom=mybottom, color='red')\n",
    "plt.bar(np.arange(len(human_pred_norm))+width, model_pred_norm-mybottom, width, bottom=mybottom, color='blue')\n",
    "plt.ylabel('estimated strength (normalized)')\n",
    "plt.legend(('people','model'))\n",
    "plt.show()\n",
    "\n",
    "r = pearsonr(human_pred_norm,model_pred_norm)[0]\n",
    "print('correlation between human and model predictions; r = ' + str(round(r,3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 2 (10 points) </h3>\n",
    "<br>\n",
    "In the cell below, briefly comment on whether or not the model is a good account of the human judgments. Which of the six scenarios do you think indicates that Player A is the strongest? Which of the scenarios indicates the Player A is the weakest? Does the model agree? Your reponse should be one or two paragraphs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model in general is good account of the human judgments because after the six scenarios, human conginition of player A strength and machine's strength level matched very closely. However, the model performed poorly in the early scenarios such as 1 and 2, which may be due to not having enough information/ having more uncertainty in the early stages of scenarios. Out of the six scenarios, I thought scenario 6 was the strongest indicator of player A being the strongest. For scenario 4, I thought it indicated Player A weakest. \n",
    "\n",
    "The model agrees with my intution with scenario 6 as the indicator of Player A being strongest. This makes sense because Player A was the only undefeated player until 6th scenario, and scenario 5 really increased the probability of Player A being the strongest by adding new players into the match against player A. In addition, the model also agreed with my scenario 4 indicating Player A the weakest. This was mostly due to uncertainty of Player A's strength against Player B, who did very well against other players in scenario 4. As a result, both the model and I were not able to clearly tell whether Player A was truly the strongest player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 3 (15 points) </h3>\n",
    "<br>\n",
    "In the last problem, your job is to modify the probabilistic program to make the scenario slightly more complex. We have reimplemented the probabilistic program below with all the functions duplicated with a \"_v2\" flag.\n",
    "<br><br>\n",
    "The idea is that players may also have a \"temper,\" which is a binary variable that is either `True` or `False`. Like `strength`, a player's temper is a PERSISENT variable that should be added to the world state. The probability that any given player has a temper is 0.2. Once a temper is sampled, its value persists until the world is cleared.\n",
    "<br><br>\n",
    "How does the temper variable change the model? If ALL the players on a team have a temper, the overall team strength (sum strength) is divided by 4! Otherwise, there is no effect.\n",
    "<br><br>\n",
    "Here is the assignment:\n",
    "<ul>\n",
    "    <li>First, write complete the function `has_temper` below such that each name is assigned a binary temper value that is persistent like strength. Store this temper value in the world state using `dict_temper.` [Hint: This function will look a lot like the `strength_v2` function]</li>\n",
    "    <li>Second, modify the `team_strength_v2` function to account for the case that all team members have a temper.</li>\n",
    "    <li>Third, run the simulation below comparing the case where Tom and Sue both have tempers to the case where Tom and Sue do not have tempers. How does this influence our inference about Bob's strength? Why? Write a one paragraph response in the very last cell explaining your answer.\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If Tom and Sue do not have tempers...\n",
      "  Estimate of Bob's strength: mean = 11.814868227024009; effective n = 17281\n",
      "If Tom and Sue BOTH have tempers...\n",
      "  Estimate of Bob's strength: mean = 10.663921360144775; effective n = 1928\n"
     ]
    }
   ],
   "source": [
    "class world_v2():\n",
    "    def __init__(self):\n",
    "        self.dict_strength = {}\n",
    "        self.dict_temper = {}\n",
    "    def clear(self): # used when sampling over possible world\n",
    "        self.dict_strength = {}\n",
    "        self.dict_temper = {}\n",
    "\n",
    "def strength_v2(name):\n",
    "    if name not in W.dict_strength:\n",
    "        W.dict_strength[name] = abs(random.gauss(10,3))\n",
    "    return W.dict_strength[name]\n",
    "\n",
    "def lazy_v2(name):\n",
    "    return random.random() < 0.1\n",
    "        \n",
    "def has_temper(name):\n",
    "    # each player has a 0.2 probability of having a temper\n",
    "    # TODO: YOUR CODE GOES HERE\n",
    "    # pass # delete this line when done\n",
    "    if name not in W.dict_temper:\n",
    "        W.dict_temper[name] = random.random() < 0.2\n",
    "    return W.dict_temper[name]\n",
    "    \n",
    "def team_strength_v2(team):\n",
    "    # team : list of names\n",
    "    mysum = 0.\n",
    "    for name in team:\n",
    "        if lazy_v2(name):\n",
    "            mysum += (strength_v2(name) / 2.)\n",
    "        else:\n",
    "            mysum += strength_v2(name)\n",
    "    # if all of the players have a temper, divide sum strength by 4\n",
    "    ## TODO : YOUR CODE GOES HERE    \n",
    "    check_true = True\n",
    "    for name in team:\n",
    "        if has_temper(name) == False:\n",
    "            check_true = False\n",
    "    if check_true == True:\n",
    "        mysum /= 4\n",
    "    return mysum\n",
    "\n",
    "def winner_v2(team1,team2):\n",
    "    # team1 : list of names\n",
    "    # team2 : list of names\n",
    "    if team_strength_v2(team1) > team_strength_v2(team2):\n",
    "        return team1\n",
    "    else:\n",
    "        return team2\n",
    "\n",
    "def beat_v2(team1,team2):\n",
    "    return winner_v2(team1,team2) == team1\n",
    "\n",
    "W = world_v2()\n",
    "\n",
    "f_return = lambda : strength_v2('bob')\n",
    "list_f_conditions = [lambda : not has_temper('tom'), lambda : not has_temper('sue'), lambda : beat_v2( ['bob', 'mary'],['tom', 'sue'] ), lambda : beat_v2( ['bob', 'sue'],  ['tom', 'jim'] )]\n",
    "samples = rejection_sampler(f_return, list_f_conditions, nsamp=100000)\n",
    "mean_strength = np.mean(samples)\n",
    "print(\"If Tom and Sue do not have tempers...\")\n",
    "print(\"  Estimate of Bob's strength: mean = \" + str(mean_strength) + \"; effective n = \" + str(len(samples)))\n",
    "\n",
    "list_f_conditions = [lambda : has_temper('tom'), lambda : has_temper('sue'), lambda : beat_v2( ['bob', 'mary'],['tom', 'sue'] ), lambda : beat_v2( ['bob', 'sue'],  ['tom', 'jim'] )]\n",
    "samples = rejection_sampler(f_return, list_f_conditions, nsamp=100000)\n",
    "mean_strength = np.mean(samples)\n",
    "print(\"If Tom and Sue BOTH have tempers...\")\n",
    "print(\"  Estimate of Bob's strength: mean = \" + str(mean_strength) + \"; effective n = \" + str(len(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR SHORT ANSWER GOES HERE. Does conditioning on temper influence our inference about Bob's strength?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning on temper influences our inference about Bob's strength. This is because when all the players in the opponent group have temper, their overall strength decreases 4 times. This means, the actual strength of Bob is more uncertain. In other words, we lose confidence in Bob's strength, and this is reflected in the decreased estimate of Bob's strength when both Sue and Tom have tempers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
